Epoch 1/10
























1250/1250 [==============================] - 51s 40ms/step - loss: 1.5035 - accuracy: 0.4568 - val_loss: 1.1949 - val_accuracy: 0.5735
Epoch 2/10


























1250/1250 [==============================] - 54s 43ms/step - loss: 1.1060 - accuracy: 0.6108 - val_loss: 1.0429 - val_accuracy: 0.6337
Epoch 3/10
























1250/1250 [==============================] - 51s 40ms/step - loss: 0.9377 - accuracy: 0.6736 - val_loss: 0.9991 - val_accuracy: 0.6545
Epoch 4/10


























1250/1250 [==============================] - 55s 44ms/step - loss: 0.8270 - accuracy: 0.7109 - val_loss: 0.9744 - val_accuracy: 0.6641
Epoch 5/10
























1250/1250 [==============================] - 49s 39ms/step - loss: 0.7389 - accuracy: 0.7419 - val_loss: 1.0170 - val_accuracy: 0.6640
Epoch 6/10
























1250/1250 [==============================] - 50s 40ms/step - loss: 0.6501 - accuracy: 0.7721 - val_loss: 1.0212 - val_accuracy: 0.6642
Epoch 7/10
























1250/1250 [==============================] - 50s 40ms/step - loss: 0.5705 - accuracy: 0.8011 - val_loss: 1.0762 - val_accuracy: 0.6670
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 30, 30, 32)        896
 conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248
 conv2d_2 (Conv2D)           (None, 26, 26, 32)        9248
 max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0
 )
 flatten (Flatten)           (None, 5408)              0
 dense (Dense)               (None, 64)                346176
 dense_1 (Dense)             (None, 10)                650
=================================================================
Total params: 366,218
Trainable params: 366,218
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10


























1250/1250 [==============================] - 55s 43ms/step - loss: 1.4925 - accuracy: 0.4591 - val_loss: 1.1901 - val_accuracy: 0.5758
Epoch 2/10

























1250/1250 [==============================] - 51s 41ms/step - loss: 1.0767 - accuracy: 0.6234 - val_loss: 1.0273 - val_accuracy: 0.6371
Epoch 3/10
























1250/1250 [==============================] - 51s 41ms/step - loss: 0.9111 - accuracy: 0.6813 - val_loss: 1.0274 - val_accuracy: 0.6412
Epoch 4/10
























1250/1250 [==============================] - 50s 40ms/step - loss: 0.7974 - accuracy: 0.7198 - val_loss: 0.9542 - val_accuracy: 0.6735
Epoch 5/10
























1250/1250 [==============================] - 49s 39ms/step - loss: 0.6999 - accuracy: 0.7545 - val_loss: 1.0077 - val_accuracy: 0.6523
Epoch 6/10























1250/1250 [==============================] - 49s 39ms/step - loss: 0.6076 - accuracy: 0.7853 - val_loss: 1.0570 - val_accuracy: 0.6618
Epoch 7/10
























1250/1250 [==============================] - 49s 39ms/step - loss: 0.5210 - accuracy: 0.8163 - val_loss: 1.1170 - val_accuracy: 0.6641
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_3 (Conv2D)           (None, 30, 30, 32)        896
 conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248
 conv2d_5 (Conv2D)           (None, 26, 26, 32)        9248
 max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0
 2D)
 flatten_1 (Flatten)         (None, 5408)              0
 dense_2 (Dense)             (None, 64)                346176
 dense_3 (Dense)             (None, 10)                650
=================================================================
Total params: 366,218
Trainable params: 366,218
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
























1250/1250 [==============================] - 52s 41ms/step - loss: 1.4661 - accuracy: 0.4713 - val_loss: 1.1897 - val_accuracy: 0.5774
Epoch 2/10

























1250/1250 [==============================] - 52s 41ms/step - loss: 1.0644 - accuracy: 0.6256 - val_loss: 1.0387 - val_accuracy: 0.6382
Epoch 3/10
























1250/1250 [==============================] - 51s 41ms/step - loss: 0.8878 - accuracy: 0.6903 - val_loss: 0.9552 - val_accuracy: 0.6700
Epoch 4/10




















1250/1250 [==============================] - 41s 33ms/step - loss: 0.7653 - accuracy: 0.7318 - val_loss: 0.9715 - val_accuracy: 0.6647
Epoch 5/10




















1250/1250 [==============================] - 43s 35ms/step - loss: 0.6633 - accuracy: 0.7693 - val_loss: 0.9812 - val_accuracy: 0.6715
Epoch 6/10




















1250/1250 [==============================] - 42s 34ms/step - loss: 0.5614 - accuracy: 0.8049 - val_loss: 1.0107 - val_accuracy: 0.6672
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_6 (Conv2D)           (None, 30, 30, 32)        896
 conv2d_7 (Conv2D)           (None, 28, 28, 32)        9248
 conv2d_8 (Conv2D)           (None, 26, 26, 32)        9248
 max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0
 2D)
 flatten_2 (Flatten)         (None, 5408)              0
 dense_4 (Dense)             (None, 64)                346176
 dense_5 (Dense)             (None, 10)                650
=================================================================
Total params: 366,218
Trainable params: 366,218
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10




















1250/1250 [==============================] - 43s 34ms/step - loss: 1.4579 - accuracy: 0.4779 - val_loss: 1.1728 - val_accuracy: 0.5807
Epoch 2/10




















1250/1250 [==============================] - 42s 34ms/step - loss: 1.0458 - accuracy: 0.6314 - val_loss: 1.0593 - val_accuracy: 0.6335
Epoch 3/10




















1250/1250 [==============================] - 42s 33ms/step - loss: 0.8747 - accuracy: 0.6938 - val_loss: 0.9646 - val_accuracy: 0.6708
Epoch 4/10




















1250/1250 [==============================] - 42s 33ms/step - loss: 0.7465 - accuracy: 0.7378 - val_loss: 0.9903 - val_accuracy: 0.6634
Epoch 5/10




















1250/1250 [==============================] - 42s 33ms/step - loss: 0.6351 - accuracy: 0.7763 - val_loss: 0.9943 - val_accuracy: 0.6708
Epoch 6/10




















1250/1250 [==============================] - 42s 33ms/step - loss: 0.5394 - accuracy: 0.8098 - val_loss: 1.0738 - val_accuracy: 0.6645
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_9 (Conv2D)           (None, 30, 30, 32)        896
 conv2d_10 (Conv2D)          (None, 28, 28, 32)        9248
 conv2d_11 (Conv2D)          (None, 26, 26, 32)        9248
 max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0
 2D)
 flatten_3 (Flatten)         (None, 5408)              0
 dense_6 (Dense)             (None, 64)                346176
 dense_7 (Dense)             (None, 10)                650
=================================================================
Total params: 366,218
Trainable params: 366,218
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
  88/1250 [=>............................] - ETA: 37s - loss: 2.1903 - accuracy: 0.1854
 149/1250 [==>...........................] - ETA: 35s - loss: 2.0526 - accuracy: 0.2385
 213/1250 [====>.........................] - ETA: 33s - loss: 1.9483 - accuracy: 0.2832
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
 275/1250 [=====>........................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
Total params: 366,218....................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
Total params: 366,218....................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
Total params: 366,218....................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
/home/cipher73/Downloads/Honours/ACML/2023/Labs/ACML-CNN-GROUP/kfold_cifar10.py:114: MatplotlibDeprecationWarning: The close_event function was deprecated in Matplotlib 3.6 and will be removed two minor releases later. Use callbacks.process('close_event', CloseEvent(...)) instead.
  plt.close()
/home/cipher73/Downloads/Honours/ACML/2023/Labs/ACML-CNN-GROUP/kfold_cifar10.py:125: MatplotlibDeprecationWarning: The close_event function was deprecated in Matplotlib 3.6 and will be removed two minor releases later. Use callbacks.process('close_event', CloseEvent(...)) instead.
  plt.close()
Total params: 366,218....................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
Total params: 366,218....................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
Total params: 366,218....................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098
Total params: 366,218....................] - ETA: 31s - loss: 1.8791 - accuracy: 0.3098