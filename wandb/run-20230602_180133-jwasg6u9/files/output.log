Epoch 1/10














1250/1250 [==============================] - 37s 29ms/step - loss: 1.4455 - accuracy: 0.4843 - val_loss: 1.1422 - val_accuracy: 0.6024
Epoch 2/10

















1250/1250 [==============================] - 36s 29ms/step - loss: 1.0570 - accuracy: 0.6297 - val_loss: 1.0456 - val_accuracy: 0.6352
Epoch 3/10


















1250/1250 [==============================] - 37s 29ms/step - loss: 0.9221 - accuracy: 0.6783 - val_loss: 1.0495 - val_accuracy: 0.6360
Epoch 4/10
















1250/1250 [==============================] - 36s 28ms/step - loss: 0.8288 - accuracy: 0.7101 - val_loss: 0.9653 - val_accuracy: 0.6717
Epoch 5/10

















1250/1250 [==============================] - 35s 28ms/step - loss: 0.7431 - accuracy: 0.7388 - val_loss: 0.9744 - val_accuracy: 0.6673
Epoch 6/10


















1250/1250 [==============================] - 39s 31ms/step - loss: 0.6616 - accuracy: 0.7670 - val_loss: 1.0356 - val_accuracy: 0.6570
Epoch 7/10


















1250/1250 [==============================] - 38s 31ms/step - loss: 0.5829 - accuracy: 0.7933 - val_loss: 1.0590 - val_accuracy: 0.6599
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 30, 30, 32)        896
 conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248
 max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0
 )
 flatten (Flatten)           (None, 6272)              0
 dense (Dense)               (None, 64)                401472
 dense_1 (Dense)             (None, 10)                650
=================================================================
Total params: 412,266
Trainable params: 412,266
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
















1250/1250 [==============================] - 35s 28ms/step - loss: 1.4293 - accuracy: 0.4867 - val_loss: 1.1589 - val_accuracy: 0.5953
Epoch 2/10

















1250/1250 [==============================] - 36s 29ms/step - loss: 1.0539 - accuracy: 0.6289 - val_loss: 1.0211 - val_accuracy: 0.6448
Epoch 3/10

















1250/1250 [==============================] - 36s 29ms/step - loss: 0.9204 - accuracy: 0.6764 - val_loss: 0.9893 - val_accuracy: 0.6623
Epoch 4/10



















1250/1250 [==============================] - 40s 32ms/step - loss: 0.8233 - accuracy: 0.7114 - val_loss: 0.9985 - val_accuracy: 0.6594
Epoch 5/10
















1250/1250 [==============================] - 34s 27ms/step - loss: 0.7428 - accuracy: 0.7403 - val_loss: 0.9973 - val_accuracy: 0.6553
Epoch 6/10



















1250/1250 [==============================] - 40s 32ms/step - loss: 0.6671 - accuracy: 0.7671 - val_loss: 1.0020 - val_accuracy: 0.6674
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_2 (Conv2D)           (None, 30, 30, 32)        896
 conv2d_3 (Conv2D)           (None, 28, 28, 32)        9248
 max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0
 2D)
 flatten_1 (Flatten)         (None, 6272)              0
 dense_2 (Dense)             (None, 64)                401472
 dense_3 (Dense)             (None, 10)                650
=================================================================
Total params: 412,266
Trainable params: 412,266
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
















1250/1250 [==============================] - 35s 28ms/step - loss: 1.4279 - accuracy: 0.4861 - val_loss: 1.1647 - val_accuracy: 0.5897
Epoch 2/10

















1250/1250 [==============================] - 35s 28ms/step - loss: 1.0606 - accuracy: 0.6279 - val_loss: 1.0132 - val_accuracy: 0.6442
Epoch 3/10
















1250/1250 [==============================] - 34s 27ms/step - loss: 0.9262 - accuracy: 0.6795 - val_loss: 1.0316 - val_accuracy: 0.6407
Epoch 4/10

















1250/1250 [==============================] - 36s 29ms/step - loss: 0.8365 - accuracy: 0.7085 - val_loss: 0.9919 - val_accuracy: 0.6622
Epoch 5/10















1250/1250 [==============================] - 34s 27ms/step - loss: 0.7554 - accuracy: 0.7386 - val_loss: 0.9918 - val_accuracy: 0.6638
Epoch 6/10


















1250/1250 [==============================] - 37s 29ms/step - loss: 0.6737 - accuracy: 0.7670 - val_loss: 1.0079 - val_accuracy: 0.6607
Epoch 7/10

















1250/1250 [==============================] - 36s 29ms/step - loss: 0.5977 - accuracy: 0.7942 - val_loss: 1.0509 - val_accuracy: 0.6608
Epoch 8/10
















1250/1250 [==============================] - 35s 28ms/step - loss: 0.5178 - accuracy: 0.8210 - val_loss: 1.1175 - val_accuracy: 0.6539
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_4 (Conv2D)           (None, 30, 30, 32)        896
 conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248
 max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0
 2D)
 flatten_2 (Flatten)         (None, 6272)              0
 dense_4 (Dense)             (None, 64)                401472
 dense_5 (Dense)             (None, 10)                650
=================================================================
Total params: 412,266
Trainable params: 412,266
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10

















1250/1250 [==============================] - 37s 29ms/step - loss: 1.4811 - accuracy: 0.4689 - val_loss: 1.2492 - val_accuracy: 0.5551
Epoch 2/10


















1250/1250 [==============================] - 37s 30ms/step - loss: 1.1111 - accuracy: 0.6085 - val_loss: 1.0787 - val_accuracy: 0.6204
Epoch 3/10
















1250/1250 [==============================] - 35s 28ms/step - loss: 0.9507 - accuracy: 0.6710 - val_loss: 0.9973 - val_accuracy: 0.6523
Epoch 4/10
















1250/1250 [==============================] - 33s 26ms/step - loss: 0.8577 - accuracy: 0.7011 - val_loss: 1.0119 - val_accuracy: 0.6513
Epoch 5/10
















1250/1250 [==============================] - 36s 28ms/step - loss: 0.7800 - accuracy: 0.7281 - val_loss: 1.0488 - val_accuracy: 0.6444
Epoch 6/10

















1250/1250 [==============================] - 35s 28ms/step - loss: 0.7117 - accuracy: 0.7519 - val_loss: 1.0092 - val_accuracy: 0.6636
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_6 (Conv2D)           (None, 30, 30, 32)        896
 conv2d_7 (Conv2D)           (None, 28, 28, 32)        9248
 max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0
 2D)
 flatten_3 (Flatten)         (None, 6272)              0
 dense_6 (Dense)             (None, 64)                401472
 dense_7 (Dense)             (None, 10)                650
=================================================================
Total params: 412,266
Trainable params: 412,266
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
  87/1250 [=>............................] - ETA: 31s - loss: 2.1509 - accuracy: 0.2162
 156/1250 [==>...........................] - ETA: 30s - loss: 2.0121 - accuracy: 0.2594
 224/1250 [====>.........................] - ETA: 29s - loss: 1.9187 - accuracy: 0.2952
 299/1250 [======>.......................] - ETA: 26s - loss: 1.8490 - accuracy: 0.3244
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 374/1250 [=======>......................] - ETA: 24s - loss: 1.7911 - accuracy: 0.3476
 Layer (type)                Output Shape              Param #   911 - accuracy: 0.3476
 Layer (type)                Output Shape              Param #   911 - accuracy: 0.3476
 Layer (type)                Output Shape              Param #   911 - accuracy: 0.3476
/home/cipher73/Downloads/Honours/ACML/2023/Labs/ACML-CNN-GROUP/kfold_cifar10.py:114: MatplotlibDeprecationWarning: The close_event function was deprecated in Matplotlib 3.6 and will be removed two minor releases later. Use callbacks.process('close_event', CloseEvent(...)) instead.
  plt.close()
/home/cipher73/Downloads/Honours/ACML/2023/Labs/ACML-CNN-GROUP/kfold_cifar10.py:125: MatplotlibDeprecationWarning: The close_event function was deprecated in Matplotlib 3.6 and will be removed two minor releases later. Use callbacks.process('close_event', CloseEvent(...)) instead.
313/313 [==============================] - 1s 5ms/step Param #   911 - accuracy: 0.3476
313/313 [==============================] - 1s 5ms/step Param #   911 - accuracy: 0.3476
1/1 [==============================] - 0s 17ms/steptep Param #   911 - accuracy: 0.3476
1/1 [==============================] - 0s 17ms/steptep Param #   911 - accuracy: 0.3476